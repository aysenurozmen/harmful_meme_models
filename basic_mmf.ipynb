{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba500ad-b740-4318-8bca-272e29cbc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf310d8-c3ec-485b-9344-cce1745684ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "\n",
    "# Image transformation\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # pads or shrinks the image to 224*224\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3532980a-eb24-48aa-b856-57cdf9a082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMF dataset class\n",
    "class MmfDataset(Dataset):\n",
    "    def __init__(self, data, image_folder, image_transform, tokenizer):\n",
    "        self.data = data\n",
    "        self.image_folder = image_folder\n",
    "        self.image_transform = image_transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "\n",
    "        # Load and preprocess image\n",
    "        image_path = self.image_folder + entry[\"image\"]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.image_transform(image)\n",
    "\n",
    "        # Tokenize and obtain text embeddings using BERT\n",
    "        text = entry[\"text\"]\n",
    "        tokens = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            text_embedding = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Label encoding\n",
    "        label = entry[\"labels\"][0]\n",
    "        if label == \"not harmful\":\n",
    "            encoded_label = 0\n",
    "        elif label == \"somewhat harmful\":\n",
    "            encoded_label = 1\n",
    "        elif label == \"very harmful\":\n",
    "            encoded_label = 2\n",
    "\n",
    "        # Convert encoded_label to a PyTorch tensor\n",
    "        encoded_label_tensor = torch.tensor(encoded_label)\n",
    "\n",
    "        return image, text_embedding, encoded_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3cf5d7-76b3-473a-8cca-529ba91a56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unpack the batch into separate lists for images, text_embeddings, and labels\n",
    "    images, text_embeddings, labels = zip(*batch)\n",
    "\n",
    "    # Stack images and text_embeddings into tensors\n",
    "    images = torch.stack(images)\n",
    "    text_embeddings = torch.stack(text_embeddings)\n",
    "\n",
    "    # Stack labels into a tensor\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return images, text_embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b94116-d97e-4893-a767-6977f4aed9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"C:\\\\Users\\\\aysen\\\\Documents\\\\GitHub\\\\harmful_meme_models\\\\data\\\\datasets\\\\memes\\\\defaults\\\\annotations\\\\train.jsonl\"\n",
    "test_dataset_path = \"C:\\\\Users\\\\aysen\\\\Documents\\\\GitHub\\\\harmful_meme_models\\\\data\\\\datasets\\\\memes\\\\defaults\\\\annotations\\\\test.jsonl\"\n",
    "image_folder = \"C:\\\\Users\\\\aysen\\\\Documents\\\\GitHub\\\\harmful_meme_models\\\\data\\\\datasets\\\\memes\\\\defaults\\\\images\\\\\"\n",
    "\n",
    "# Read the JSON string for training dataset from the file\n",
    "with open(train_dataset_path, \"r\", encoding='cp437') as file:\n",
    "    train_dataset_str = file.read()\n",
    "    file.close()\n",
    "\n",
    "# Read the JSON string for test dataset from the file\n",
    "with open(test_dataset_path, \"r\", encoding='cp437') as file:\n",
    "    test_dataset_str = file.read()\n",
    "    file.close()\n",
    "\n",
    "# Parse the JSON string\n",
    "train_dataset = [json.loads(entry) for entry in train_dataset_str.strip().split('\\n')]\n",
    "test_dataset = [json.loads(entry) for entry in test_dataset_str.strip().split('\\n')]\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader instances for both training and validation sets\n",
    "mmf_dataset_train = MmfDataset(data=train_dataset, image_folder=image_folder, image_transform=image_transform, tokenizer=tokenizer)\n",
    "data_loader_train = DataLoader(mmf_dataset_train, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "mmf_dataset_val = MmfDataset(data=val_dataset, image_folder=image_folder, image_transform=image_transform, tokenizer=tokenizer)\n",
    "data_loader_val = DataLoader(mmf_dataset_val, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "mmf_dataset_test = MmfDataset(data=test_dataset, image_folder=image_folder, image_transform=image_transform, tokenizer=tokenizer)\n",
    "data_loader_test = DataLoader(mmf_dataset_test, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45677b6-b365-400c-b40d-55aa045d2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class MmfClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_feature_size, text_feature_size, num_classes):\n",
    "        \n",
    "        super(MmfClassifier, self).__init__()\n",
    "        self.shared_layer = nn.Linear(image_feature_size + text_feature_size, 256)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.output_layer = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, image_data, text_data):\n",
    "\n",
    "        # Reshape to (batch_size, channels*height*width)\n",
    "        flattened_image_data = image_data.view(image_data.size(0), -1)\n",
    "\n",
    "        # Reshape to (batch_size, sequence_length*embedding_size)\n",
    "        flattened_text_data = text_data.view(text_data.size(0), -1)\n",
    "\n",
    "        # Combine visual and textual features \n",
    "        combined_features = torch.cat((flattened_image_data, flattened_text_data), dim=1)\n",
    "        shared_output = self.relu(self.shared_layer(combined_features))\n",
    "        x = self.dropout(shared_output)\n",
    "        output = self.output_layer(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3829c4a5-a330-4333-aa6e-55d86d6657a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "image_feature_size = 3*224*224 # Image feature size\n",
    "text_feature_size = 768  # Text feature size\n",
    "num_classes = 3  # Number of classes\n",
    "\n",
    "# Instantiate the model\n",
    "model = MmfClassifier(image_feature_size, text_feature_size, num_classes)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d504ae5-7f6e-4312-a25f-3084f544e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First entry in the dataset:\n",
      "{\n",
      "  \"id\": \"covid_memes_18\",\n",
      "  \"image\": \"covid_memes_18.png\",\n",
      "  \"labels\": [\n",
      "    \"somewhat harmful\",\n",
      "    \"individual\"\n",
      "  ],\n",
      "  \"text\": \"Bernie or Elizabeth?\\nBe informed.Compare them on the issues that matter.\\nIssue: Who makes the dankest memes?\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"First entry in the dataset:\")\n",
    "print(json.dumps(dataset[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ff50e6-a570-4f53-ac09-0a019cd04a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.0272610187530518, Validation Loss: 0.9543550202721044, Validation Accuracy: 0.30016583747927034\n",
      "Epoch 2/100, Training Loss: 0.984973132610321, Validation Loss: 0.8530751905943218, Validation Accuracy: 0.6417910447761194\n",
      "Epoch 3/100, Training Loss: 1.633434534072876, Validation Loss: 0.9965877909409372, Validation Accuracy: 0.6135986733001658\n",
      "Epoch 4/100, Training Loss: 0.8003036379814148, Validation Loss: 0.8768869669813859, Validation Accuracy: 0.6417910447761194\n",
      "Epoch 5/100, Training Loss: 0.8227801322937012, Validation Loss: 0.8548082113265991, Validation Accuracy: 0.6417910447761194\n",
      "Epoch 6/100, Training Loss: 0.5822281837463379, Validation Loss: 0.9917216677414743, Validation Accuracy: 0.6417910447761194\n",
      "Epoch 7/100, Training Loss: 0.6507325768470764, Validation Loss: 0.8963533200715718, Validation Accuracy: 0.6417910447761194\n",
      "Early stopping after 6 epochs without improvement.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m best_model \u001b[38;5;241m=\u001b[39m MyModel()\n\u001b[0;32m     58\u001b[0m best_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MyModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for training\n",
    "num_epochs = 100\n",
    "patience = 5  # Number of epochs with no improvement after which training will be stopped\n",
    "best_val_loss = float('inf')\n",
    "current_patience = 0\n",
    "\n",
    "# Training and Validation loops\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for batch in data_loader_train:\n",
    "        images, text_embeddings, labels = batch\n",
    "        outputs = model(images, text_embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_val in data_loader_val:\n",
    "            images_val, text_embeddings_val, labels_val = batch_val\n",
    "            outputs_val = model(images_val, text_embeddings_val)\n",
    "            loss_val = criterion(outputs_val, labels_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs_val, 1)\n",
    "            correct_predictions += (predicted == labels_val).sum().item()\n",
    "            total_samples += labels_val.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(data_loader_val)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {avg_val_loss}, Validation Accuracy: {accuracy}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        current_patience = 0\n",
    "        # Save the model if needed\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        current_patience += 1\n",
    "\n",
    "    if current_patience >= patience:\n",
    "        print(f\"Early stopping after {epoch} epochs without improvement.\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e611ed2-5df9-4206-a689-a4e830e02517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.97%\n",
      "Precision: 0.42\n",
      "Recall: 0.65\n",
      "F1-score: 0.51\n",
      "Confusion Matrix:\n",
      "[[230   0   0]\n",
      " [103   0   0]\n",
      " [ 21   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysen\\anaconda3\\envs\\hate_speech_classification\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "best_model = MmfClassifier(image_feature_size=image_feature_size, text_feature_size=text_feature_size, num_classes=num_classes)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_test in data_loader_test:\n",
    "        images_test, text_embeddings_test, labels_test = batch_test\n",
    "        outputs_test = best_model(images_test, text_embeddings_test)\n",
    "        _, predicted_test = torch.max(outputs_test, 1)\n",
    "        all_predictions.extend(predicted_test.cpu().numpy())\n",
    "        all_ground_truth.extend(labels_test.cpu().numpy())\n",
    "\n",
    "# Convert predictions and ground truth to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_ground_truth = np.array(all_ground_truth)\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(all_ground_truth, all_predictions)\n",
    "precision = precision_score(all_ground_truth, all_predictions, average='weighted')\n",
    "recall = recall_score(all_ground_truth, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_ground_truth, all_predictions, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_ground_truth, all_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272d5f2-fa05-41ad-9060-f15aee255508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
