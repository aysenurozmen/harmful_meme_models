{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba500ad-b740-4318-8bca-272e29cbc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision.transforms.functional import to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3532980a-eb24-48aa-b856-57cdf9a082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMF dataset class\n",
    "class MmfDataset(Dataset):\n",
    "    def __init__(self, data, image_folder, image_transform, tokenizer):\n",
    "        self.data = data\n",
    "        self.image_folder = image_folder\n",
    "        self.image_transform = image_transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "\n",
    "        # Load and preprocess image\n",
    "        image_path = self.image_folder + entry[\"image\"]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.image_transform(image)\n",
    "\n",
    "        # Tokenize and obtain text embeddings using BERT\n",
    "        text = entry[\"text\"]\n",
    "        tokens = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            text_embedding = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Label encoding\n",
    "        label = entry[\"labels\"][0]\n",
    "        if label == \"not harmful\":\n",
    "            encoded_label = 0\n",
    "        elif label == \"somewhat harmful\":\n",
    "            encoded_label = 1\n",
    "        elif label == \"very harmful\":\n",
    "            encoded_label = 2\n",
    "\n",
    "        # Convert encoded_label to a PyTorch tensor\n",
    "        encoded_label_tensor = torch.tensor(encoded_label)\n",
    "\n",
    "        return image, text_embedding, encoded_label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3cf5d7-76b3-473a-8cca-529ba91a56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unpack the batch into separate lists for images, text_embeddings, and labels\n",
    "    images, text_embeddings, labels = zip(*batch)\n",
    "\n",
    "    # Stack images and text_embeddings into tensors\n",
    "    images = torch.stack(images)\n",
    "    text_embeddings = torch.stack(text_embeddings)\n",
    "\n",
    "    # Stack labels into a tensor\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return images, text_embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45677b6-b365-400c-b40d-55aa045d2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "image_feature_size = 3*224*224 # Image feature size\n",
    "text_feature_size = 768  # Text feature size\n",
    "num_classes = 3  # Number of classes\n",
    "\n",
    "# Instantiate the model\n",
    "class MmfClassifier(nn.Module):\n",
    "    def __init__(self, image_feature_size, text_feature_size, num_classes):\n",
    "        super(MmfClassifier, self).__init__()\n",
    "\n",
    "        self.shared_layer = nn.Linear(image_feature_size + text_feature_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, image_data, text_data):\n",
    "\n",
    "        # Reshape to (batch_size, channels * height * width)\n",
    "        flattened_image_data = image_data.view(image_data.size(0), -1)\n",
    "\n",
    "        # Reshape to (batch_size, sequence_length * embedding_size)\n",
    "        flattened_text_data = text_data.view(text_data.size(0), -1)\n",
    "        \n",
    "        combined_features = torch.cat((flattened_image_data, flattened_text_data), dim=1)\n",
    "        shared_output = self.relu(self.shared_layer(combined_features))\n",
    "        output = self.output_layer(shared_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3829c4a5-a330-4333-aa6e-55d86d6657a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MmfClassifier(image_feature_size, text_feature_size, num_classes)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Tokenizer and BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "\n",
    "# Image transformation\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # pads or shrinks the image to 224*224\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b94116-d97e-4893-a767-6977f4aed9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:\\\\Users\\\\aysen\\\\Documents\\\\GitHub\\\\harmful_meme_models\\\\data\\\\datasets\\\\memes\\\\defaults\\\\annotations\\\\train.jsonl\"\n",
    "image_folder = \"C:\\\\Users\\\\aysen\\\\Documents\\\\GitHub\\\\harmful_meme_models\\\\data\\\\datasets\\\\memes\\\\defaults\\\\images\\\\\"\n",
    "\n",
    "# Read the JSON string from the file\n",
    "with open(dataset_path, \"r\", encoding='cp437') as file:\n",
    "    dataset_str = file.read()\n",
    "    file.close()\n",
    "\n",
    "# Parse the JSON string\n",
    "dataset = [json.loads(entry) for entry in dataset_str.strip().split('\\n')]\n",
    "\n",
    "# Create DataLoader\n",
    "mmf_dataset = MmfDataset(data=dataset, image_folder=image_folder, image_transform=image_transform, tokenizer=tokenizer)\n",
    "data_loader = DataLoader(mmf_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d504ae5-7f6e-4312-a25f-3084f544e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First entry in the dataset:\n",
      "{\n",
      "  \"id\": \"covid_memes_18\",\n",
      "  \"image\": \"covid_memes_18.png\",\n",
      "  \"labels\": [\n",
      "    \"somewhat harmful\",\n",
      "    \"individual\"\n",
      "  ],\n",
      "  \"text\": \"Bernie or Elizabeth?\\nBe informed.Compare them on the issues that matter.\\nIssue: Who makes the dankest memes?\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"First entry in the dataset:\")\n",
    "print(json.dumps(dataset[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff17714-1f27-4527-9c77-5cd4209fa693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6063514947891235\n",
      "Epoch 2/5, Loss: 0.23800086975097656\n",
      "Epoch 3/5, Loss: 1.2541553974151611\n",
      "Epoch 4/5, Loss: 0.26917997002601624\n",
      "Epoch 5/5, Loss: 0.5931230187416077\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "\n",
    "        images, text_embeddings, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, text_embeddings)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee787f0-100e-462f-8d6d-5e0851c01e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
